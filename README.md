Данная программа предназначена для применения в различных задачах автономной сортировки с использованием алгоритма нейросети YOLO с помощью роботизированных систем. Результатом ее работы являются координаты каждого 
распознаного объекта относительно рабочей поверхности, а также сформированный отчет в EXCEL файле со всей необходимой информацией. Отклонение при определении координат объектов приблизительно 3 мм! 
Ниже будет подробная инструкцияпо применению программы. 

Краткое описание работы программы: На вход принимается видео поток изображений с камеры, по нажатию клавиши "Space" делается снимок, по которому определяется местоположение объектов,
их класс и другие полезные данные, после чего автоматически все эти данные добавляются в отчет в EXCEL файле.

1) Склонируйте репозиторий к себе на компьютер
2) Откройте текстовый файл конфигурации settings.txt, находящийся в директории for_scripts и укажите все необходимые параметры камеры (Коэффиценты дисторсии, параметры матрицы камеры, высоту камеры,
ее расположение относительно начала координатной плоскости), ориентируясь на пример в файле.
3) Откройте файл main.py
В данной программе используется модель нейросети YOLO, обученная мною для распознавания трех объектов: гайка M5, бесколлекторный мотор, антенна радиосвязи. Если вы хотите использовать
свою модель, то укажите к ней полный путь в аргументе model_path в функции detect_objects. После чего установите свой источник видео в скобках cap = cv2VideoCapture(1), где 0 встроенная или первая подключенная камера, 1 вторая
подключенная камера и т.д. После запустите основную функцию main. В течение некоторого времени на экране появится окно с изображением с камеры. Чтобы привести программу в действие необходимо нажать клавишу "Space", после чего в 
консоли появится информация о распознанном изображении, которая добавится в автоматически созданный файл report.xlsx в директории for_report. Чтобы завершить программу следует нажать клавишу 'q'. При повторном запуске программы данные об
объектах продолжат добавляться в отчет. Фотографии каждого распознанного объекта для сверки находятся в img2excel в директории for_script

Примечание: данный вариант управления с помощью клавиатуры носит демонстрационный харрактер, вы можете модифицировать программу под свои задачи и цели.

Примечание: погрешность распознавания зависит от качества калибровки вашей камеры, поэтому можете ее откалибровать воспользовавшись скриптом cam_callib.py или же любым другим возможным способом

Примечание: Прежде чем запускать программу повторно, закройте файл отчета report.xlsx. Если вы хотите очистить отчет, то просто удалите его, он создатся автоматически при запуске программы

Демонстрация работы алгоритма:
1) Вывод видеопотока на экран с распознанными объектами. В скобках указаны координаты центров объекта (ед. изм. м) в формате X, Y. На фото ниже располагаются объекты, а также выведены координаты, благодаря которым можете убедиться в том,
что отклонение при определении координат минимально (в центре отклонение составляет 1 мм, по бокам 2-3 мм из-за не самых оптимальных настроек камеры)
<img width="939" height="689" alt="image" src="https://github.com/user-attachments/assets/aaae58fa-7952-4f02-b715-c012e34cdecf" />
2) После нажатия клавиши "Space" кропнутые изображения каждого объекта сохраняются в в директорию img2excel, после чего данные об объектах добавляются в отчет:
<img width="2443" height="844" alt="image" src="https://github.com/user-attachments/assets/e58b8e45-71c7-4517-8d4d-7800d56178b9" />
Пример изображения объекта для сверки:
м![obj_n11](https://github.com/user-attachments/assets/abf3a63e-bc93-4483-a524-30d97bc80fe6)

3) Также информация об объектах в качестве дебага выводится в консоль
4) По завершении программы через клавишу "q" все окна программы закрываются, отчет и изображения при этом сохраняются



   
